#packages -- beautiful soup for the text/ selenium to navigate the page
from bs4 import BeautifulSoup as soup
from urllib.request import urlopen as uReq
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
import time
import pandas as pd
import re
driver= webdriver.Chrome(ChromeDriverManager().install())



#%%

#Getting Links of the main foodpantries page
def getLinksOfMainPage(a):
    # getting urls and reading it
    my_url = a
    driver.get(my_url)
    uClient = uReq(my_url)
    page_html = uClient.read()
    uClient.close()
    page_soup = soup(page_html, "html.parser")
    
    #get links
    link_hold = []
    for link in page_soup.find_all('a'):
        link_hold.append(link.get('href'))
    
    #remove duplicates
    i = 1
    while i < len(link_hold):
        if link_hold[i] == link_hold[i-1]:
            del link_hold[i-1]
            i += 1
        else:
            i += 1
            
    return link_hold

#%%
# returns a list(url of regions) within a list(states)
def Individual_Links_to_States():
    all_region_links = []
    z = getLinksOfMainPage("https://www.foodpantries.org/")
    all_links = z[19:70] #get rid of non-state links
    i1 = 0
    List_Of_States = []
    
    while i1 < len (all_links):
        temp = all_links[i1]
        List_Of_States.append(temp[32:])
        driver.get(all_links[i1])
        all_region_links.append(getLinksOfMainPage(all_links[i1]))
        time.sleep(2)
        i1 += 1
        
        
    i2 = 0
    while i2 < len(all_region_links): #data cleaning
        all_region_links[i2] = all_region_links[i2][9:-8]
        i2 += 1
    return [List_Of_States, all_region_links]

#%%
#names of individual food banks taking the link to the region page as its argument
def Get_Individual_Food_Banks(linktoStatePage):
    sauce = uReq(linktoStatePage)
    page_soup = soup(sauce,"lxml")
    FoodBankName = []
    temp2 = []
    combinedtemp = []
    
    for FoodBank in page_soup.find_all('h2'):
        FoodBankName.append(FoodBank.text)
    
    for items in page_soup.find_all('p'):
        temp2.append(items.text)
    
    i1 = 0
    i2 = 1
    while i1 < len(FoodBankName):
        combinedtemp.append(FoodBankName[i1]+ temp2[i2]+ temp2[i2+1])
        i1 += 1
        i2 += 2
    return combinedtemp

#%%

#matches certain patterns in strings - returns index of these matches
def match_pattern(pattern1, string): 
    regex = re.compile(pattern1)
    temp1 = []
    for i, match in enumerate(regex.finditer(string)):
        a= [match.span()]
        temp1 += a
    return temp1

#creates list of Food Bank Name, Location, Description
def sort_clean_Food_Bank_info(temp1, string):
    temp2 = []
    if len(temp1) < 1:
        temp2.append(temp2)
    if len(temp1) == 1:
        temp2.append(string[:(temp1[0][0])])
        temp2.append(string[(temp1[0][1]):])
    else:
        temp2.append(string[:(temp1[0][0])])
        temp2.append(string[(temp1[0][1]):(temp1[1][0])])
        temp2.append(string[(temp1[1][0]):(temp1[1][1])])
        temp2.append(string[(temp1[1][1]):])
    return temp2

def clean_the_FoodBankName(temp1, string): 
    temp2 = temp1[0][0]
    return string[:(temp2)]


#%%
#Creates Dataset

temp =  Individual_Links_to_States()
States = temp[0] #names of states
Regions_Links = temp[1] #links to run Get_Individual_Food_Banks


z1 = 0
i1 = 0
i2 = 0
i3 = 0
data = pd.DataFrame(columns = ["Food Bank Name", "State", "Region",  "Zip Code", "Phone Number", "Description"])
while i1 < len(Regions_Links): #i1 iterates thru states
    while i2 < len(Regions_Links[i1]): #i2 iterates thru Regions in each state
        temp = Get_Individual_Food_Banks(Regions_Links[i1][i2]) #list of food banks in certain region
        while i3 < len(temp):
            data.loc[z1,"State"] = (States[i1]) 
            data.loc[z1, "Region"] = ((Regions_Links[i1][i2])[35:]) 
            cleaned_FoodBankInfo = sort_clean_Food_Bank_info(match_pattern("                ",temp[i3]),temp[i3])
            if len(cleaned_FoodBankInfo) <= 2:
                data.loc[z1,"Food Bank Name"] = clean_the_FoodBankName(match_pattern("\\\n",cleaned_FoodBankInfo[0]), cleaned_FoodBankInfo[0])
                data.loc[z1,"Zip Code"] = cleaned_FoodBankInfo[1][-7:]
                if len(match_pattern("\(\w{3}\)",cleaned_FoodBankInfo[1])) != 0: #has (***) zip code
                    data.loc[z1,"Phone Number"] = cleaned_FoodBankInfo[1][0:14]
                    data.loc[z1,"Description"] = cleaned_FoodBankInfo[1][14:]
                else:
                    data.loc[z1,"Phone Number"] = cleaned_FoodBankInfo[1][0:12]
                    data.loc[z1,"Description"] = cleaned_FoodBankInfo[1][12:]

            else:
                data.loc[z1,"Food Bank Name"] = clean_the_FoodBankName(match_pattern("\\\n", cleaned_FoodBankInfo[0]), cleaned_FoodBankInfo[0])
                data.loc[z1,"Zip Code"] = cleaned_FoodBankInfo[1][-7:]
                if len(match_pattern("\(\w{3}\)", cleaned_FoodBankInfo[3])) != 0: #has (***) zip code
                    data.loc[z1,"Phone Number"] = cleaned_FoodBankInfo[3][0:14]
                    data.loc[z1,"Description"] = cleaned_FoodBankInfo[3][14:]
                else: 
                    data.loc[z1,"Phone Number"] = cleaned_FoodBankInfo[3][0:12]
                    data.loc[z1,"Description"] = cleaned_FoodBankInfo[3][12:]
            z1 += 1
            i3 += 1
            #print ("FoodBank#: "+ str(i3))
            #print ("DataRow#: "+ str(z1))
        i2 += 1
        i3 = 0
        print("Region#: "+ str(i2))
    i1 += 1
    i2 = 0
    i3 = 0
    print ("State#: "+ str(i1))

data.to_excel("FoodBankdata.xlsx")
